<?xml version="1.0" encoding="UTF-8" ?>
<configuration scan="true" scanPeriod="1800 seconds"
               debug="true">

    <property name="USER_HOME" value="logs"/>
    <property scope="context" name="FILE_NAME" value="sdxd-cms-log"/>
    <property scope="context" name="FILE_SIZE" value="500MB"/>
    <property name="system" value="DEV_CMS"/>
    <property name="GELF-ADDRESS" value="10.253.106.15"/>
    <property name="GELF-PORT" value="12213"/>

    <timestamp key="byDateTime" datePattern="yyyy-MM-dd"/>

    <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <pattern>${system} %d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n
            </pattern>
        </encoder>
        <!-- 此日志appender是为开发使用，只配置最底级别，控制台输出的日志级别是大于或等于此级别的日志信息-->
        <filter class="ch.qos.logback.classic.filter.ThresholdFilter">
            <level>DEBUG</level>
        </filter>
    </appender>

    <appender name="file-info" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <append>true</append>
        <prudent>false</prudent>
        <file>${catalina.home}/logs/${FILE_NAME}-INFO.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <!-- rollover daily hours -->
            <fileNamePattern>
                ${catalina.home}/logs/${byDateTime}/${FILE_NAME}-INFO-%d{yyyy-MM-dd-HH}-%i.log.zip
            </fileNamePattern>
            <timeBasedFileNamingAndTriggeringPolicy
                    class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <!-- or whenever the file size reaches 100MB -->
                <maxFileSize>${FILE_SIZE}</maxFileSize>
            </timeBasedFileNamingAndTriggeringPolicy>
            <minIndex>1</minIndex>
            <maxIndex>30</maxIndex>
        </rollingPolicy>
        <encoder>
            <pattern>
                ${system} %-4relative %d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{35} - %msg%n
            </pattern>
        </encoder>
        <!-- 此日志文件只记录info级别，不记录大于info级别的日志 -->
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>INFO</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
    </appender>
    <!-- 异步输出 -->
    <appender name="async-file-info" class="ch.qos.logback.classic.AsyncAppender">
        <!-- 不丢失日志.默认的,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 -->
        <discardingThreshold>0</discardingThreshold>
        <!-- 更改默认的队列的深度,该值会影响性能.默认值为256 -->
        <queueSize>512</queueSize>
        <!-- 添加附加的appender,最多只能添加一个 -->
        <appender-ref ref="file-info"/>
    </appender>

    <appender name="file-debug" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <append>true</append>
        <prudent>false</prudent>
        <file>${catalina.home}/logs/${FILE_NAME}-DEBUG.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <!-- rollover daily hours -->
            <fileNamePattern>
                ${catalina.home}/logs/${byDateTime}/${FILE_NAME}-DEBUG-%d{yyyy-MM-dd-HH}-%i.log.zip
            </fileNamePattern>
            <timeBasedFileNamingAndTriggeringPolicy
                    class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <!-- or whenever the file size reaches 100MB -->
                <maxFileSize>${FILE_SIZE}</maxFileSize>
            </timeBasedFileNamingAndTriggeringPolicy>
            <minIndex>1</minIndex>
            <maxIndex>30</maxIndex>
        </rollingPolicy>
        <encoder>
            <pattern>
                ${system} %-4relative %d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{35} - %msg%n
            </pattern>
        </encoder>
        <!-- 此日志文件只记录DEBUG级别，不记录大于DEBUG级别的日志 -->
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>DEBUG</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
    </appender>

    <!-- 异步输出 -->
    <appender name="async-file-debug" class="ch.qos.logback.classic.AsyncAppender">
        <!-- 不丢失日志.默认的,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 -->
        <discardingThreshold>0</discardingThreshold>
        <!-- 更改默认的队列的深度,该值会影响性能.默认值为256 -->
        <queueSize>512</queueSize>
        <!-- 添加附加的appender,最多只能添加一个 -->
        <appender-ref ref="file-debug"/>
    </appender>

    <appender name="file-warn" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <append>true</append>
        <prudent>false</prudent>
        <file>${catalina.home}/logs/${FILE_NAME}-WARN.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <!-- rollover daily hours -->
            <fileNamePattern>
                ${catalina.home}/logs/${byDateTime}/${FILE_NAME}-WARN-%d{yyyy-MM-dd-HH}-%i.log.zip
            </fileNamePattern>
            <timeBasedFileNamingAndTriggeringPolicy
                    class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <!-- or whenever the file size reaches 100MB -->
                <maxFileSize>${FILE_SIZE}</maxFileSize>
            </timeBasedFileNamingAndTriggeringPolicy>
            <minIndex>1</minIndex>
            <maxIndex>30</maxIndex>
        </rollingPolicy>
        <encoder>
            <pattern>
                ${system} %-4relative %d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{35} - %msg%n
            </pattern>
        </encoder>
        <!-- 此日志文件只记录warn级别，不记录大于warn级别的日志 -->
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>WARN</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
    </appender>

    <appender name="async-file-warn" class="ch.qos.logback.classic.AsyncAppender">
        <!-- 不丢失日志.默认的,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 -->
        <discardingThreshold>0</discardingThreshold>
        <!-- 更改默认的队列的深度,该值会影响性能.默认值为256 -->
        <queueSize>512</queueSize>
        <!-- 添加附加的appender,最多只能添加一个 -->
        <appender-ref ref="file-warn"/>
    </appender>

    <appender name="file-error" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <append>true</append>
        <prudent>false</prudent>
        <file>${catalina.home}/logs/${FILE_NAME}-ERROR.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <!-- rollover daily hours -->
            <fileNamePattern>
                ${catalina.home}/logs/${byDateTime}/${FILE_NAME}-ERROR-%d{yyyy-MM-dd-HH}-%i.log.zip
            </fileNamePattern>
            <timeBasedFileNamingAndTriggeringPolicy
                    class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <!-- or whenever the file size reaches 100MB -->
                <maxFileSize>${FILE_SIZE}</maxFileSize>
            </timeBasedFileNamingAndTriggeringPolicy>
            <minIndex>1</minIndex>
            <maxIndex>30</maxIndex>
        </rollingPolicy>
        <encoder>
            <pattern>
                ${system} %-4relative %d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{35} - %msg%n
            </pattern>
        </encoder>
        <!-- 此日志文件只记录ERROR级别，不记录大于ERROR级别的日志 -->
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>ERROR</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
    </appender>

    <appender name="async-file-error" class="ch.qos.logback.classic.AsyncAppender">
        <!-- 不丢失日志.默认的,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 -->
        <discardingThreshold>0</discardingThreshold>
        <!-- 更改默认的队列的深度,该值会影响性能.默认值为256 -->
        <queueSize>512</queueSize>
        <!-- 添加附加的appender,最多只能添加一个 -->
        <appender-ref ref="file-error"/>
    </appender>


    <appender name="GELF" class="de.siegmar.logbackgelf.GelfTcpAppender">
        <graylogHost>${GELF-ADDRESS}</graylogHost>
        <graylogPort>${GELF-PORT}</graylogPort>
        <connectTimeout>15000</connectTimeout>
        <reconnectInterval>300</reconnectInterval>
        <maxRetries>2</maxRetries>
        <retryDelay>3000</retryDelay>
        <layout class="de.siegmar.logbackgelf.GelfLayout">
            <originHost>localhost</originHost>
            <includeRawMessage>false</includeRawMessage>
            <includeMarker>true</includeMarker>
            <includeMdcData>true</includeMdcData>
            <includeCallerData>false</includeCallerData>
            <includeRootCauseData>false</includeRootCauseData>
            <includeLevelName>false</includeLevelName>
            <shortPatternLayout class="ch.qos.logback.classic.PatternLayout">
                <pattern>%m%nopex</pattern>
            </shortPatternLayout>
            <fullPatternLayout class="ch.qos.logback.classic.PatternLayout">
                <pattern>%m</pattern>
            </fullPatternLayout>
            <staticField>app_name:${system}</staticField>
            <staticField>os_arch:${os.arch}</staticField>
            <staticField>os_name:${os.name}</staticField>
            <staticField>os_version:${os.version}</staticField>
        </layout>
    </appender>

    <appender name="ASYNC-GELF" class="ch.qos.logback.classic.AsyncAppender">
        <appender-ref ref="GELF"/>
    </appender>


    <!--
        为单独的包配置日志级别，若root的级别大于此级别， 此处级别也会输出
        应用场景：生产环境一般不会将日志级别设置为trace或debug，
           其它包则会按root的级别输出日志
    -->

    <logger name="java.sql.PreparedStatement" level="DEBUG"/>
    <logger name="java.sql.Connection" level="DEBUG"/>
    <logger name="java.sql.Statement" level="DEBUG"/>
    <logger name="com.ibatis" level="DEBUG"/>
    <logger name="com.ibatis.common.jdbc.SimpleDataSource" level="DEBUG"/>
    <logger name="com.ibatis.common.jdbc.ScriptRunner" level="DEBUG"/>
    <logger name="com.ibatis.sqlmap.engine.impl.SqlMapClientDelegate" level="DEBUG"/>
    <logger name="org.quartz" level="WARN"/>
    <logger name="org.apache.activemq" level="WARN"/>
    <logger name="org.springframework.jms.connection" level="WARN"/>
    <logger name="org.apache.zookeeper" level="WARN"></logger>

    <!-- mybatis打印sql语句，仅开发环境使用-->
    <logger name="log4j.logger.com.ibatis" level="DEBUG"/>
    <logger name="log4j.logger.com.ibatis.common.jdbc.SimpleDataSource" level="DEBUG"/>
    <logger name="log4j.logger.com.ibatis.common.jdbc.ScriptRunner" level="DEBUG"/>
    <logger name="log4j.logger.com.ibatis.sqlmap.engine.impl.SqlMapClientDelegate" level="DEBUG"/>
    <logger name="log4j.logger.java.sql.Connection" level="DEBUG"/>
    <logger name="log4j.logger.java.sql.Statement" level="DEBUG"/>
    <logger name="log4j.logger.java.sql.PreparedStatement" level="DEBUG"/>
    <logger name="org.mongodb.driver.cluster" level="WARN"/>


    <!-- 生产环境，将此级别配置为适合的级别，以免日志文件太多或影响程序性能 -->
    <root level="DEBUG">
        <appender-ref ref="STDOUT"/>
        <appender-ref ref="async-file-info"/>
        <appender-ref ref="async-file-warn"/>
        <appender-ref ref="async-file-debug"/>
        <appender-ref ref="async-file-error"/>
        <appender-ref ref="ASYNC-GELF"/>
    </root>
</configuration>